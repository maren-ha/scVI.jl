<!DOCTYPE html>
<html lang="en"><head><meta charset="UTF-8"/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><title>The scVAE model · scVI</title><script data-outdated-warner src="assets/warner.js"></script><link href="https://cdnjs.cloudflare.com/ajax/libs/lato-font/3.0.0/css/lato-font.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/juliamono/0.045/juliamono.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.4/css/fontawesome.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.4/css/solid.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.4/css/brands.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.13.24/katex.min.css" rel="stylesheet" type="text/css"/><script>documenterBaseURL="."</script><script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js" data-main="assets/documenter.js"></script><script src="siteinfo.js"></script><script src="../versions.js"></script><link class="docs-theme-link" rel="stylesheet" type="text/css" href="assets/themes/documenter-dark.css" data-theme-name="documenter-dark" data-theme-primary-dark/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="assets/themes/documenter-light.css" data-theme-name="documenter-light" data-theme-primary/><script src="assets/themeswap.js"></script></head><body><div id="documenter"><nav class="docs-sidebar"><a class="docs-logo" href="index.html"><img src="assets/logo.svg" alt="scVI logo"/></a><div class="docs-package-name"><span class="docs-autofit"><a href="index.html">scVI</a></span></div><form class="docs-search" action="search.html"><input class="docs-search-query" id="documenter-search-query" name="q" type="text" placeholder="Search docs"/></form><ul class="docs-menu"><li><a class="tocitem" href="index.html">Getting started</a></li><li><a class="tocitem" href="DataProcessing.html">Data processing</a></li><li class="is-active"><a class="tocitem" href="scVAE.html">The scVAE model</a><ul class="internal"><li><a class="tocitem" href="#Encoder"><span>Encoder</span></a></li><li><a class="tocitem" href="#Decoder"><span>Decoder</span></a></li><li><a class="tocitem" href="#VAE-model"><span>VAE model</span></a></li></ul></li><li><a class="tocitem" href="scLDVAE.html">The scLDVAE model</a></li><li><a class="tocitem" href="Training.html">Model training</a></li><li><a class="tocitem" href="Evaluation.html">Model evaluation</a></li></ul><div class="docs-version-selector field has-addons"><div class="control"><span class="docs-label button is-static is-size-7">Version</span></div><div class="docs-selector control is-expanded"><div class="select is-fullwidth is-size-7"><select id="documenter-version-selector"></select></div></div></div></nav><div class="docs-main"><header class="docs-navbar"><nav class="breadcrumb"><ul class="is-hidden-mobile"><li class="is-active"><a href="scVAE.html">The scVAE model</a></li></ul><ul class="is-hidden-tablet"><li class="is-active"><a href="scVAE.html">The scVAE model</a></li></ul></nav><div class="docs-right"><a class="docs-edit-link" href="https://github.com/maren-ha/scVI.jl/blob/origin/main/docs/src/scVAE.md" title="Edit on GitHub"><span class="docs-icon fab"></span><span class="docs-label is-hidden-touch">Edit on GitHub</span></a><a class="docs-settings-button fas fa-cog" id="documenter-settings-button" href="#" title="Settings"></a><a class="docs-sidebar-button fa fa-bars is-hidden-desktop" id="documenter-sidebar-button" href="#"></a></div></header><article class="content" id="documenter-page"><h1 id="The-scVAE-model"><a class="docs-heading-anchor" href="#The-scVAE-model">The scVAE model</a><a id="The-scVAE-model-1"></a><a class="docs-heading-anchor-permalink" href="#The-scVAE-model" title="Permalink"></a></h1><h2 id="Encoder"><a class="docs-heading-anchor" href="#Encoder">Encoder</a><a id="Encoder-1"></a><a class="docs-heading-anchor-permalink" href="#Encoder" title="Permalink"></a></h2><p>The implementation is based on the Python implementation of the  <a href="https://github.com/scverse/scvi-tools/blob/b33b42a04403842591c04e414c8bb4099eaf7006/scvi/nn/_base_components.py#L202"><code>scvi-tools</code> encoder</a>.</p><article class="docstring"><header><a class="docstring-binding" id="scVI.scEncoder" href="#scVI.scEncoder"><code>scVI.scEncoder</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia hljs">mutable struct scEncoder</code></pre><p>Julia implementation of the encoder of a single-cell VAE model corresponding to the <a href="https://github.com/scverse/scvi-tools/blob/b33b42a04403842591c04e414c8bb4099eaf7006/scvi/nn/_base_components.py#L202"><code>scvi-tools</code> encoder</a>. Collects all information on the encoder parameters and stores the basic encoder and mean and variance encoders.  Can be constructed using keywords. </p><p><strong><strong>Keyword arguments</strong></strong></p><ul><li><code>encoder</code>: <code>Flux.Chain</code> of fully connected layers realising the first part of the encoder (before the split in mean and variance). For details, see the source code of <code>FC_layers</code> in <code>src/Utils</code>.</li><li><code>mean_encoder</code>: <code>Flux.Dense</code> fully connected layer realising the latent mean encoder </li><li><code>n_input</code>: input dimension = number of genes/features</li><li><code>n_hidden</code>: number of hidden units to use in each hidden layer </li><li><code>n_output</code>: output dimension of the encoder = dimension of latent space </li><li><code>n_layers</code>: number of hidden layers in encoder and decoder </li><li><code>var_activation</code>: whether or not to use an activation function for the variance layer in the encoder</li><li><code>var_encoder</code>: <code>Flux.Dense</code> fully connected layer realising the latent variance encoder </li><li><code>var_eps</code>: numerical stability constant to add to the variance in the reparameterisation of the latent representation</li><li><code>z_transformation</code>: whether to apply a <code>softmax</code> transformation the latent z if assuming a lognormal instead of a normal distribution</li></ul></div><a class="docs-sourcelink" target="_blank" href="https://github.com/maren-ha/scVI.jl/blob/f11c0e173d8acfcfe1dadda6f6dc13b034b0615b/src/EncoderDecoder.jl#L5-L24">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="scVI.scEncoder-Tuple{Int64, Int64}" href="#scVI.scEncoder-Tuple{Int64, Int64}"><code>scVI.scEncoder</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia hljs">scEncoder(
    n_input::Int, 
    n_output::Int;
    activation_fn::Function=relu, # to use in FC_layers
    bias::Bool=true,
    n_hidden::Union{Int,Vector{Int}}=128,
    n_layers::Int=1,
    distribution::Symbol=:normal,
    dropout_rate::Float32=0.1f0,
    use_activation::Bool=true,
    use_batch_norm::Bool=true,
    use_layer_norm::Bool=false,
    var_activation=nothing,
    var_eps::Float32=Float32(1e-4)
)</code></pre><p>Constructor for an <code>scVAE</code> encoder. Initialises an <code>scEncoder</code> object according to the input parameters.  Julia implementation of the <a href="https://github.com/scverse/scvi-tools/blob/b33b42a04403842591c04e414c8bb4099eaf7006/scvi/nn/_base_components.py#L202"><code>scvi-tools</code> encoder</a>.</p><p><strong><strong>Arguments:</strong></strong></p><ul><li><code>n_input</code>: input dimension = number of genes/features</li><li><code>n_output</code>: output dimension of the encoder = latent space dimension</li></ul><p><strong><strong>Keyword arguments:</strong></strong></p><ul><li><code>activation_fn</code>: function to use as activation in all encoder neural network layers </li><li><code>bias</code>: whether or not to use bias parameters in the encoder neural network layers</li><li><code>n_hidden</code>: number of hidden units to use in each hidden layer (if an <code>Int</code> is passed, this number is used in all hidden layers,    alternatively an array of <code>Int</code>s can be passed, in which case the kth element corresponds to the number of units in the kth layer.</li><li><code>n_layers</code>: number of hidden layers in encoder </li><li><code>distribution</code> :whether to use a <code>:normal</code> or lognormal (<code>:ln</code>) distribution for the latent z  </li><li><code>dropout_rate</code>: dropout to use in all encoder layers. Setting the rate to 0.0 corresponds to no dropout. </li><li><code>use_activation</code>: whether or not to use an activation function in the encoder neural network layers; if <code>false</code>, overrides choice in <code>actication_fn</code></li><li><code>use_batch_norm</code>: whether or not to apply batch normalization in the encoder layers</li><li><code>use_layer_norm</code>: whether or not to apply layer normalization in the encoder layers</li><li><code>var_activation</code>: whether or not to use an activation function for the variance layer in the encoder</li><li><code>var_eps</code>: numerical stability constant to add to the variance in the reparameterisation of the latent representation</li></ul></div><a class="docs-sourcelink" target="_blank" href="https://github.com/maren-ha/scVI.jl/blob/f11c0e173d8acfcfe1dadda6f6dc13b034b0615b/src/EncoderDecoder.jl#L44-L83">source</a></section></article><h2 id="Decoder"><a class="docs-heading-anchor" href="#Decoder">Decoder</a><a id="Decoder-1"></a><a class="docs-heading-anchor-permalink" href="#Decoder" title="Permalink"></a></h2><p>The implementation is based on the Python implementation of the  <a href="https://github.com/scverse/scvi-tools/blob/b33b42a04403842591c04e414c8bb4099eaf7006/scvi/nn/_base_components.py#L308"><code>scvi-tools</code> decoder</a>.</p><article class="docstring"><header><a class="docstring-binding" id="scVI.scDecoder" href="#scVI.scDecoder"><code>scVI.scDecoder</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia hljs">mutable struct scDecoder &lt;: AbstractDecoder</code></pre><p>Julia implementation of the decoder for a single-cell VAE model corresponding to the <a href="https://github.com/scverse/scvi-tools/blob/b33b42a04403842591c04e414c8bb4099eaf7006/scvi/nn/_base_components.py#L308"><code>scvi-tools</code> decoder</a>. Collects all information on the decoder parameters and stores the decoder parts.  Can be constructed using keywords. </p><p><strong><strong>Keyword arguments</strong></strong></p><ul><li><code>n_input</code>: input dimension = dimension of latent space </li><li><code>n_hidden</code>: number of hidden units to use in each hidden layer (if an <code>Int</code> is passed, this number is used in all hidden layers,   alternatively an array of <code>Int</code>s can be passed, in which case the kth element corresponds to the number of units in the kth layer.</li><li><code>n_output</code>: output dimension of the decoder = number of genes/features</li><li><code>n_layers</code>: number of hidden layers in decoder </li><li><code>px_decoder</code>: <code>Flux.Chain</code> of fully connected layers realising the first part of the decoder (before the split in mean, dispersion and dropout decoder). For details, see the source code of <code>FC_layers</code> in <code>src/Utils</code>.</li><li><code>px_dropout_decoder</code>: if the generative distribution is zero-inflated negative binomial (<code>gene_likelihood = :zinb</code> in the <code>scVAE</code> model construction): <code>Flux.Dense</code> layer, else <code>nothing</code>.</li><li><code>px_r_decoder</code>: decoder for the dispersion parameter. If generative distribution is not some (zero-inflated) negative binomial, it is <code>nothing</code>. Else, it is a parameter vector  or a <code>Flux.Dense</code>, depending on whether the dispersion is estimated per gene (<code>dispersion = :gene</code>), or per gene and cell (<code>dispersion = :gene_cell</code>)  </li><li><code>px_scale_decoder</code>: decoder for the mean of the reconstruction, <code>Flux.Chain</code> of a <code>Dense</code> layer followed by <code>softmax</code> activation</li><li><code>use_batch_norm</code>: whether or not to apply batch normalization in the decoder layers</li><li><code>use_layer_norm</code>: whether or not to apply layer normalization in the decoder layers </li></ul></div><a class="docs-sourcelink" target="_blank" href="https://github.com/maren-ha/scVI.jl/blob/f11c0e173d8acfcfe1dadda6f6dc13b034b0615b/src/EncoderDecoder.jl#L247-L267">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="scVI.scDecoder-Tuple{Any, Any}" href="#scVI.scDecoder-Tuple{Any, Any}"><code>scVI.scDecoder</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia hljs">scDecoder(n_input, n_output; 
    activation_fn::Function=relu,
    bias::Bool=true,
    dispersion::Symbol=:gene,
    dropout_rate::Float32=0.0f0,
    gene_likelihood::Symbol=:zinb,
    n_hidden::Union{Int,Vector{Int}}=128,
    n_layers::Int=1, 
    use_activation::Bool=true,
    use_batch_norm::Bool=true,
    use_layer_norm::Bool=false
)</code></pre><p>Constructor for an <code>scVAE</code> decoder. Initialises an <code>scDecoder</code> object according to the input parameters.  Julia implementation of the <a href="https://github.com/scverse/scvi-tools/blob/b33b42a04403842591c04e414c8bb4099eaf7006/scvi/nn/_base_components.py#L308"><code>scvi-tools</code> decoder</a>.</p><p><strong><strong>Arguments:</strong></strong></p><ul><li><code>n_input</code>: input dimension of the decoder = latent space dimension</li><li><code>n_output</code>: output dimension = number of genes/features in the data </li></ul><p><strong><strong>Keyword arguments:</strong></strong></p><ul><li><code>activation_fn</code>: function to use as activation in all decoder neural network layers </li><li><code>bias</code>: whether or not to use bias parameters in the decoder neural network layers</li><li><code>dispersion</code>: whether to estimate the dispersion parameter for the (zero-inflated) negative binomial generative distribution per gene (<code>:gene</code>) or per gene and cell (<code>:gene_cell</code>) </li><li><code>dropout_rate</code>: dropout to use in all decoder layers. Setting the rate to 0.0 corresponds to no dropout. </li><li><code>n_hidden</code>: number of hidden units to use in each hidden layer (if an <code>Int</code> is passed, this number is used in all hidden layers,    alternatively an array of <code>Int</code>s can be passed, in which case the kth element corresponds to the number of units in the kth layer.</li><li><code>n_layers</code>: number of hidden layers in decoder </li><li><code>use_activation</code>: whether or not to use an activation function in the decoder neural network layers; if <code>false</code>, overrides choice in <code>actication_fn</code></li><li><code>use_batch_norm</code>: whether or not to apply batch normalization in the decoder layers</li><li><code>use_layer_norm</code>: whether or not to apply layer normalization in the decoder layers</li></ul></div><a class="docs-sourcelink" target="_blank" href="https://github.com/maren-ha/scVI.jl/blob/f11c0e173d8acfcfe1dadda6f6dc13b034b0615b/src/EncoderDecoder.jl#L283-L317">source</a></section></article><h2 id="VAE-model"><a class="docs-heading-anchor" href="#VAE-model">VAE model</a><a id="VAE-model-1"></a><a class="docs-heading-anchor-permalink" href="#VAE-model" title="Permalink"></a></h2><p>The implementation is a basic version of the <a href="https://github.com/scverse/scvi-tools/blob/b33b42a04403842591c04e414c8bb4099eaf7006/scvi/module/_vae.py#L22"><code>scvi-tools</code> VAE object</a>. </p><article class="docstring"><header><a class="docstring-binding" id="scVI.scVAE" href="#scVI.scVAE"><code>scVI.scVAE</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia hljs">mutable struct scVAE</code></pre><p>Julia implementation of the single-cell Variational Autoencoder model corresponding to the <a href="https://github.com/scverse/scvi-tools/blob/b33b42a04403842591c04e414c8bb4099eaf7006/scvi/module/_vae.py#L22"><code>scvi-tools</code> VAE object</a>.  Collects all information on the model parameters such as distribution choices and stores the model encoder and decoder.  Can be constructed using keywords. </p><p><strong><strong>Keyword arguments</strong></strong></p><ul><li><code>n_input::Ind</code>: input dimension = number of genes/features</li><li><code>n_batch::Int=0</code>: number of batches in the data </li><li><code>n_hidden::Int=128</code>: number of hidden units to use in each hidden layer </li><li><code>n_latent::Int=10</code>: dimension of latent space </li><li><code>n_layers::Int=1</code>: number of hidden layers in encoder and decoder </li><li><code>dispersion::Symbol=:gene</code>: can be either <code>:gene</code> or <code>:gene-cell</code>. The Python <code>scvi-tools</code> options <code>:gene-batch</code> and <code>gene-label</code> are planned, but not supported yet. </li><li><code>is_trained::Bool=false</code>: indicating whether the model has been trained or not</li><li><code>dropout_rate</code>: Dropout to use in the encoder and decoder layers. Setting the rate to 0.0 corresponds to no dropout. </li><li><code>gene_likelihood::Symbol=:zinb</code>: which generative distribution to parameterize in the decoder. Can be one of <code>:nb</code> (negative binomial), <code>:zinb</code> (zero-inflated negative binomial), or <code>:poisson</code> (Poisson). </li><li><code>latent_distribution::Symbol=:normal</code>: whether or not to log-transform the input data in the encoder (for numerical stability)</li><li><code>library_log_means::Union{Nothing, Vector{Float32}}</code>: log-transformed means of library size; has to be provided when not using observed library size, but encoding it</li><li><code>library_log_vars::Union{Nothing, Vector{Float32}}</code>: log-transformed variances of library size; has to be provided when not using observed library size, but encoding it</li><li><code>log_variational</code>: whether or not to log-transform the input data in the encoder (for numerical stability)</li><li><code>loss_registry::Dict=Dict()</code>: dictionary in which to record the values of the different loss components (reconstruction error, KL divergence(s)) during training </li><li><code>use_observed_lib_size::Bool=true</code>: whether or not to use the observed library size (if <code>false</code>, library size is calculated by a dedicated encoder)</li><li><code>z_encoder::scEncoder</code>: Encoder struct of the VAE model for latent representation; see <code>scEncoder</code></li><li><code>l_encoder::Union{Nothing, scEncoder}</code>: Encoder struct of the VAE model for the library size (if <code>use_observed_lib_size==false</code>), see <code>scEncoder</code></li><li><code>decoder::AbstractDecoder</code>: Decoder struct of the VAE model; see <code>scDecoder</code></li></ul></div><a class="docs-sourcelink" target="_blank" href="https://github.com/maren-ha/scVI.jl/blob/f11c0e173d8acfcfe1dadda6f6dc13b034b0615b/src/scVAEmodel.jl#L8-L35">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="scVI.scVAE-Tuple{Int64}" href="#scVI.scVAE-Tuple{Int64}"><code>scVI.scVAE</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia hljs">scVAE(n_input::Int;
    activation_fn::Function=relu, # to be used in all FC_layers instances
    bias::Symbol=:both, # whether to use bias in all linear layers of all FC instances 
    dispersion::Symbol=:gene,
    dropout_rate::Float32=0.1f0,
    gene_likelihood::Symbol=:zinb,
    latent_distribution::Symbol=:normal,
    library_log_means=nothing,
    library_log_vars=nothing,
    log_variational::Bool=true,
    n_batch::Int=1,
    n_hidden::Union{Int,Vector{Int}}=128,
    n_latent::Int=10,
    n_layers::Int=1,
    use_activation::Symbol=:both, 
    use_batch_norm::Symbol=:both,
    use_layer_norm::Symbol=:none,
    use_observed_lib_size::Bool=true,
    var_activation=nothing,
    var_eps::Float32=Float32(1e-4),
    seed::Int=1234
)</code></pre><p>Constructor for the <code>scVAE</code> model struct. Initialises an <code>scVAE</code> model with the parameters specified in the input arguments.  Basic Julia implementation of the <a href="https://github.com/scverse/scvi-tools/blob/b33b42a04403842591c04e414c8bb4099eaf7006/scvi/module/_vae.py#L22"><code>scvi-tools</code> VAE object</a>. </p><p><strong><strong>Arguments:</strong></strong></p><ul><li><code>n_input</code>: input dimension = number of genes/features</li></ul><p><strong><strong>Keyword arguments</strong></strong></p><ul><li><code>activation_fn</code>: function to use as activation in all neural network layers of encoder and decoder </li><li><code>bias</code>: whether or not to use bias parameters in the neural network layers of encoder and decoder</li><li><code>dispersion</code>: can be either <code>:gene</code> or <code>:gene-cell</code>. The Python <code>scvi-tools</code> options <code>:gene-batch</code> and <code>gene-label</code> are planned, but not supported yet. </li><li><code>dropout_rate</code>: Dropout to use in the encoder and decoder layers. Setting the rate to 0.0 corresponds to no dropout. </li><li><code>gene_likelihood</code>: which generative distribution to parameterize in the decoder. Can be one of <code>:nb</code> (negative binomial), <code>:zinb</code> (zero-inflated negative binomial), or <code>:poisson</code> (Poisson). </li><li><code>library_log_means</code>: log-transformed means of library size; has to be provided when not using observed library size, but encoding it</li><li><code>library_log_vars</code>: log-transformed variances of library size; has to be provided when not using observed library size, but encoding it</li><li><code>log_variational</code>: whether or not to log-transform the input data in the encoder (for numerical stability)</li><li><code>n_batch</code>: number of batches in the data </li><li><code>n_hidden</code>: number of hidden units to use in each hidden layer (if an <code>Int</code> is passed, this number is used in all hidden layers,    alternatively an array of <code>Int</code>s can be passed, in which case the kth element corresponds to the number of units in the kth layer.</li><li><code>n_latent</code>: dimension of latent space </li><li><code>n_layers</code>: number of hidden layers in encoder and decoder </li><li><code>use_activation</code>: whether or not to use an activation function in the neural network layers of encoder and decoder; if <code>false</code>, overrides choice in <code>actication_fn</code></li><li><code>use_batch_norm</code>: whether to apply batch normalization in the encoder/decoder layers; can be one of <code>:encoder</code>, <code>:decoder</code>, <code>both</code>, <code>:none</code></li><li><code>use_layer_norm</code>: whether to apply layer normalization in the encoder/decoder layers; can be one of <code>:encoder</code>, <code>:decoder</code>, <code>both</code>, <code>:none</code></li><li><code>use_observed_lib_size</code>: whether or not to use the observed library size (if <code>false</code>, library size is calculated by a dedicated encoder)</li><li><code>var_activation</code>: whether or not to use an activation function for the variance layer in the encoder</li><li><code>var_eps</code>: numerical stability constant to add to the variance in the reparameterisation of the latent representation</li><li><code>seed</code>: random seed to use for initialization of model parameters; to ensure reproducibility. </li></ul></div><a class="docs-sourcelink" target="_blank" href="https://github.com/maren-ha/scVI.jl/blob/f11c0e173d8acfcfe1dadda6f6dc13b034b0615b/src/scVAEmodel.jl#L57-L110">source</a></section></article></article><nav class="docs-footer"><a class="docs-footer-prevpage" href="DataProcessing.html">« Data processing</a><a class="docs-footer-nextpage" href="scLDVAE.html">The scLDVAE model »</a><div class="flexbox-break"></div><p class="footer-message">Powered by <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> and the <a href="https://julialang.org/">Julia Programming Language</a>.</p></nav></div><div class="modal" id="documenter-settings"><div class="modal-background"></div><div class="modal-card"><header class="modal-card-head"><p class="modal-card-title">Settings</p><button class="delete"></button></header><section class="modal-card-body"><p><label class="label">Theme</label><div class="select"><select id="documenter-themepicker"><option value="documenter-light">documenter-light</option><option value="documenter-dark">documenter-dark</option></select></div></p><hr/><p>This document was generated with <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> version 0.27.25 on <span class="colophon-date" title="Friday 11 August 2023 15:48">Friday 11 August 2023</span>. Using Julia version 1.7.3.</p></section><footer class="modal-card-foot"></footer></div></div></div></body></html>
